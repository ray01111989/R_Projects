---
title: "Final Project"
author: " Rawad Bader, Alex Pomraning"
date:  "`r format(Sys.time(), '%d %B %Y')`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Final Project

### Part One
```{r Libraries, include = FALSE}
# Load the packages here
library(dplyr)
library(ggplot2)
library(plotrix)
library(readr)
library(data.table)
library(tidyverse)
library(UsingR)
library(reprex)
library(tinytex)
library(ggpubr)
library(rstatix)
library(lmtest)
library(latexpdf)
library(ggthemes)
```


```{r class-data-project}
# Make sure the data frame CSV file in the same folder of the code also make sure all packages needed have check mark indicate that they are selected in the side bar. 
## read data 
classdata <- read_csv("Classdata.csv",show_col_types = FALSE)


#Analyzing the data

classdata %>%
  group_by(Early_riser) %>%
  get_summary_stats(School_work_hours, type = "mean_sd")

```

Alex Pomraning questions\

##### group #1. 

```{r Test, warning=FALSE}
# Problem 1: using 2 sample t-test due to small sample size

# Questions
# Research Question
#Is there a significant difference in the average amount of time spent on work between early risers and non-early risers?

#Null
#There is no significant difference in the average amount of time spent on 
#school work between early risers and non-early risers.

#Alternate
#There is a significant difference in the average amount of time spent on school
#work between early risers and non-early risers.

#variable creation placing the two groups in separate cells to compare
ERiser <- classdata %>%
  filter(Early_riser == "Yes") %>%
  select(School_work_hours)

LRiser <- classdata %>%
  filter(Early_riser == "No") %>%
  select(School_work_hours)

#Random Sampling
# Convenience method used which is a non-probability method
# Assumption unmet for all applicable tests we were expected to use which was
# discussed in class
# Assumption unmet Bypassing as discussed in class, tests dubious at best.

#Independence Samples have no overlap and are independent ie only in one sample: 
#checked data points in excel to ensure they did not overlap
#Assumption met

#Assumption variable is continuous, it is time and is a classic continuous
#Assumption met

#Checking normality for assumptions

# graph the data in a histogram.
ggp <- ggplot(ERiser, aes(x= School_work_hours, color=ERiser)) +
   geom_histogram(fill=I("green"), 
      col=I("red"), binwidth = 2)+ 
  labs(x = "School_work_hours", y = "count")
ggp

# QQ_plot to see of the data flow normal distribution
qqnorm(ERiser$School_work_hours, pch = 1, frame = FALSE)
qqline(ERiser$School_work_hours, col = "steelblue", lwd = 2)

# graph the data in a histogram.
ggp <- ggplot(LRiser, aes(x= School_work_hours, color=LRiser)) +
   geom_histogram(fill=I("green"), 
      col=I("red"), binwidth = 2)+ 
  labs(x = "School_work_hours", y = "count")
ggp

# QQ_plot to see of the data flow normal distribution
qqnorm(LRiser$School_work_hours, pch = 1, frame = FALSE)
qqline(LRiser$School_work_hours, col = "steelblue", lwd = 2)

#Shapiro
shapiro.test(ERiser$School_work_hours)
shapiro.test(LRiser$School_work_hours)

#P is above 0.05 on both (0.087, 0.19)
#Assumption met

#Assumption: variance are equal
Evar <- var(ERiser$School_work_hours)
Lvar <- var(LRiser$School_work_hours)
Evar/Lvar
#Ratio close to 1 and less than 4: 1.197
#Assumption met for two sample t-test

#The p-value of F-test is p = 0.6957. Itâ€™s greater than the significance level alpha = 0.05. In conclusion, there is no significant difference between the variances of the two sets of data. Therefore, we can use the classic t-test witch assume equality of the two variances.

#Assumptions met for 2 sample t-test
#Producing test
t.test(ERiser$School_work_hours, LRiser$School_work_hours, alternative = "two.sided", var.equal = TRUE)

```

##### group #2. 
```{r test2, warning=TRUE}
# Problem 2 - Fishers exact test, using because of small sample size which 
# Fishers does better than Chi even above a 5 value per cell till around 50
# As prior this decision came about through reading about the tests and what to
# do with small sample sizes. I skipped over a basic Chi2

# Questions
# Research Question
# Is there an association between being a pet owner and being an early riser?

# Null
# There is no significant relationship between being a pet owner and being an 
# early riser.

#Alternate
#There is a significant relationship between being a pet owner and being an 
#early riser.

#Variable Creation
ConT <- table( classdata$Pet, classdata$Early_riser)
names(dimnames(ConT)) <- c("Pet", "Early riser")
ConT
#Random Sampling
# Convenience method used which is a non-probability method
# Assumption unmet for all applicable tests we were expected to use which was
# discussed in class
# Assumption unmet Bypassing as discussed in class, tests dubious at best.

#Assumption: Rows are fixed
#Assumption met

#Assumption: Independent, values do not impact one another
#Assumption met

#Assumption:Observations are mutually exclusive; can't assign them to other cell
#Assumption met

# Visualizing a percentage difference between both groups
ggbarstats(
  classdata, Pet, Early_riser,
  results.subtitle = FALSE,
  subtitle = paste0(
    "Fisher's exact test", ", p-value = ",
    ifelse(test$p.value < 0.001, "< 0.001", round(test$p.value, 3))
  )
)

#From the plot, it is clear that the proportion of pets among early riser is a little higher than among non-early riser, suggesting that there are no a relationship between the two variables.

#Assumptions met for Fishers exact test
fisher.test(ConT, conf.int = TRUE, conf.level = 0.95)

```

Rawad Bader question \

```{r classdata}

# create new data frame with a column has the cs majors and other majors. 
classdata_update <- classdata %>% 
  mutate(Group = case_when(Major == "Computer Science" ~ "CS_majors", 
                               Major != "Computer Science" ~ "other_majors"))

# graph the box plot for time Social media hours to see if they have big variability between.
box <- ggplot(classdata_update, aes(y=Social_media_hours, x=Group, color=Group)) + geom_boxplot() + scale_x_discrete(guide = guide_axis(n.dodge=3))
box
# Visualize the data by histogram
ggp <- ggplot(classdata,aes(x= Social_media_hours)) +
   geom_histogram(bins = 10,binwidth = 1.9, fill=I("#FF6347"), 
      col=I("#00FF00"))+
   labs(x = "Social Media hours", y = "count")
ggp

## Density graph 
ggp2 <- ggplot( classdata,aes(x= Social_media_hours)) + geom_histogram(aes(y = ..density..),
                   bins = 10,binwidth = 1.9, fill=I("green"), col=I("black"))+ geom_density(color = 8, fill = 10, alpha = 0.2)+
ggtitle("Standard_Mercury per lake density") + theme(plot.title = element_text(hjust = 0.5)) + 
  geom_vline(aes(xintercept=mean(Social_media_hours)), color="red", linetype="dashed", size=1) +
geom_text(aes(x=mean(Social_media_hours), y=.09, label="mean", family="Times", fontface="italic"), size=5, angle=90, vjust=-0.6, hjust=-0.1,color="red") +
geom_vline(aes(xintercept=median(Social_media_hours)), color="blue", linetype="dashed", size=1)+
geom_text(aes(x=median(Social_media_hours), y=.09, label="Median", family="Times", fontface="italic"), size=5, angle=90, vjust=-0.4, hjust=0.4,color="blue")
ggp2

# QQ_plot to see of the data flow normal distribution
ggplot (classdata,aes(sample=Social_media_hours))+
stat_qq() + stat_qq_line(col = "steelblue", lwd = 1)+
xlab("Z-scores")+
ylab("Social Media Hours")

```

### Group #1: 

1.)  Is the average time spent on social media significantly higher for Computer Science 
majors than other fields of study?  \

$H_0$ : The Computer Science majors spend equal average time on social media than other fields of study. \ 
$H_a$ : The Computer Science majors spend greater average time on social media than other fields of study \


I run summary for the school work hours for both groups. \

```{r summary1}
classdata_update %>%
  group_by(Group) %>%
  get_summary_stats(Social_media_hours, type = "mean_sd")
```

#### Preleminary test to check independent t-test assumptions \

Assumption 1: Are the two samples independents? \

Yes, since the samples from computer Science and Other Major are not related. \

Assumption 2: Are the data from each of the 2 groups follow a normal distribution? \

```{r histogram}
# creating a data frame just for computer Science 
CS_major <- subset(classdata, Major == "Computer Science")

# graph the data for Computer Science in a histogram.
ggp <- ggplot(CS_major, aes(x= Social_media_hours, color=Major)) +
   geom_histogram(fill=I("green"), 
      col=I("red"), binwidth = 2)+ 
  labs(x = "Social_media_hours", y = "Other Major")
ggp

# QQ_plot to see of the data flow normal distribution
qqnorm(classdata_update$Social_media_hours[classdata_update$Group=="CS_majors"], pch = 1, frame = FALSE)
qqline(classdata_update$Social_media_hours[classdata_update$Group=="CS_majors"], col = "steelblue", lwd = 2)

```

```{r histogram2}
# creating a data frame just for other majors 
Other_majors<-classdata[!(classdata$Major=="Computer Science"),]

# graph the data for Other_majors in a histogram.
ggp <- ggplot(Other_majors, aes(x= Social_media_hours, color=Major)) +
   geom_histogram(fill=I("green"), 
      col=I("red"), binwidth = 2)+ 
  labs(x = "Social_media_hours", y = "Other Major")
ggp

# QQ_plot to see of the data flow normal distribution
qqnorm(classdata_update$Social_media_hours[classdata_update$Group!="CS_majors"], pch = 1, frame = FALSE)
qqline(classdata_update$Social_media_hours[classdata_update$Group!="CS_majors"], col = "steelblue", lwd = 2)

```
From the output, the first group histogram and the QQ plot show indication of not normal distribution because clearly we can see the skewed in bot side of the QQ-plot where in the other data set we can see that the data set follow a normal distribution and the QQ-plot show that as well. Therefore, we can still assume normality. \

Assumption 3: Do the two populations have the same variances? \

I run the F-test for the new data farm that I created with new column named Groups. \

```{r check_variances}
#Assumption: variance are equal
CSvar <- var(classdata_update$Social_media_hours[classdata_update$Group=="CS_majors"])
Ovar <- var(classdata_update$Social_media_hours[classdata_update$Group!="CS_majors"])
CSvar/Ovar
```
In conclusion, there is no significant difference between the variances of the two sets of data. Therefore, we can use the classic t-test witch assume equality of the two variances. \

Assumption 4: were the samples Obtained using random sampling? \

No, therefore our analyses will not apply to the general population of the computer science major and non-computer science major. \

I set the **var.equal = TRUE** because as I ran the F-test for the variances it show me there are no significant difference between the variances . \

```{r t-test2, echo=FALSE, include=TRUE}
# I run T-test here to check if CS it has a grater mean then the other majors 
Computer_Science <- CS_major$Social_media_hours
Other_Majors <- Other_majors$Social_media_hours
T_test <- t.test(Computer_Science,Other_Majors, alternative = "greater", var.equal = TRUE) 
T_test
```
The p-value of the test is 0.1574, which is greater than the significance level alpha = 0.05, it means we fail to reject the null hypothesis. We can conclude that CS major average time spent social media is significantly greater from other majors average time spent with a p-value = 0.1574. \

### Group #2:

I run some bar graph Visualization to see the percentage of people like sushi or Pets. \

```{r botpolt}
# Get how many row entries we have in the data and graph them for Pet and Sushi 
e <- sum(classdata$Pet == "Yes") + sum( classdata$Pet == "No")

Graph_Sushi <- ggplot(classdata, aes(Sushi)) + geom_bar(aes(y = signif(..count../e * 100, 2), fill = Sushi), stat="count")+
    geom_text(aes( label = paste("(",signif(..count../e * 100, 2),"%",")"),
                   y= signif(..count../e * 100, 2)), stat= "count", vjust = -.5) +
    labs(y = "Percent", fill="Sushi")
Graph_Sushi

Graph_Pet <- ggplot(classdata, aes(Pet)) + geom_bar(aes(y = signif(..count../e * 100, 2), fill = Pet), stat="count")+
    geom_text(aes( label = paste("(",signif(..count../e * 100, 2),"%",")"),
                   y= signif(..count../e * 100, 2)), stat= "count", vjust = -.5) +
    labs(y = "Percent", fill="Pet")
Graph_Pet
```

1.)  Is there an association between a personâ€™s preference for sushi and pet ownership? \

$H_0$: The personâ€™s preference sushi and pet ownership are independent. \
$H_a$: The personâ€™s preference sushi and pet ownership relate to each other. \

#### Preleminary test to check independent t-test assumptions \

Assumption 1: Both variables are categorical? \

Yes, since both sushi and pet ownership variables are categorical. \

Assumption 2:  All observations are independent? \

Our observations in the data set are independent and the value of one observation in the data set does not affect the value of any other observation. \

Assumption 3: IS the cells in the contingency table are mutually exclusive? \

Yes, because none of the individuals cells belong to another individuals cell. \

Assumption 4: Expected value of cells should be 5 or greater in at least 80% of cells. \

No, it is not 80% of cells but we are so close to it and none of the cells have an expected value less than 1. \

```{r reading_data_table}
Table_data <- table(classdata$Sushi, classdata$Pet)

names(dimnames(Table_data)) <- c("Sushi", "Pet")
Table_data
```

We can see there are 3 people they do not have preference for sushi and pet ownership, 6 people they do not have preference for sushi but they have preference for pet ownership, 4 people they do have preference for sushi but not pet ownership, and 13 people they do have preference for sushi and pet ownership. \

In order to compute p-values we had to set this premature in the T-test **simulate.p.value = TRUE** when test conditions are not satisfied. \

```{r, results='asis'}
Chisq_Test <- chisq.test(Table_data, simulate.p.value = TRUE)
Chisq_Test
```

We have a chi-squared value of 0.28748. Since we get a p-Value greater than the significance level of 0.05, we fail reject the null hypothesis and conclude that the two variables are in fact independent of each other. We realized that a better test will be for this is the fisher's test because how small our data set is and we did not meet the expected value of cells should be 5 or greater in at least 80% of cells. \

### Group #3: 

1.)  An option above was to test if there was a difference in time spent on school work 
between early risers and non-early risers.  Here, we are interested in seeing if there is a 
significant difference across majors.  Using the three groupings of majors below, test to 
see if there is a significant difference in time spent on school work and if there is, 
determine which grouping spends the most time on school work. \
  
a. Biology and Neuroscience \
b. Applied Mathematics, Engineering and Computer Science \
c. Botany and Environmental Science \


$H_0$ : The mean of the three groups average spent time are equal. $\mu_{BE_majors}$ = $\mu_{AEC_majors}$  =  $\mu_{BN_majors}$ \ 
$H_a$ : The mean of the three groups average spent time are not equal. $\mu_{BE_majors}$ != $\mu_{AEC_majors}$ !=  $\mu_{BN_majors}$  \


In here I created data sets for all 3 groups. \

```{r data_BN}
# create new data frame with a column has the cs and other majors. 
classdata_update1 <- classdata %>% 
  mutate(Group = case_when(Major %in% c("Botany", "Environmental Science") ~ "BE_majors", 
                               Major %in% c("Applied Mathematics", "Engineering", "Computer Science") ~ "AEC_majors",
                               Major %in% c("Biology", "Neuroscience") ~ "BN_majors"))
```

Compute the mean and the standard deviation (SD) of school work time by groups: \

```{r summary}
classdata_update1 %>%
  group_by(Group) %>%
  get_summary_stats(School_work_hours, type = "mean_sd")
```

#### Visualization \

Create a box plot of school work time by Groups, color lines by groups: \

```{r Boxplot_Groups}
# Create a box plot comparing school working time among Groups
box <- ggplot(classdata_update1, aes(y=School_work_hours, x=Group, color=Group)) + geom_boxplot()  + scale_y_log10()+ 
  scale_x_discrete(guide = guide_axis(n.dodge=3)) + 
  ggtitle("Difference in the school working time based on the Group") + 
  theme(plot.title = element_text(hjust = 0.5, size = 10, face = "bold.italic", color = "red")) +
  theme(
    axis.title.x = element_text(size = 11, face = "bold", color = "blue"),
    axis.title.y = element_text(size = 11, face = "bold.italic", color = "blue"),
    axis.text.x = element_text(face = "bold.italic", color = "black", size = 6)
  ) + 
  geom_jitter(position=position_jitter(0.2))
box 
```

```{r plot3 }
#plotting the all graphs to check the data set visualization.
par(mfrow=c(1,2))
plot(res.aov, which=1:6)
``` 

assumptions: \

1) sample is drew random \
Our sample wasnâ€™t randomly collected, nor randomization was done after collection. Therefore, our analyses cannot be applied to the general population.  \
2) independent groups \
Observation was made from analyzing the data in both sets and we established that none of our variables depends on other variables. \

3) we are assuming the distributions are normal \

I graph the QQ plot for the majors in the class data set to check if it follow a string line and see if it is close to normal distribution. \

```{r QQ_plot, echo=TRUE}
# Build the linear model for all groups 
model  <- lm(School_work_hours ~ Group, data = classdata_update1)
# Create a QQ plot of residuals
ggqqplot(residuals(model))
```
We determined that the data set very close to a normal distribution We conculed it is normal. \ 

From the output, the p-values is greater than the significance level 0.05 implying that the distribution of the data are not significantly different from the normal distribution. In other words, we can assume the normality. \\

4) Homogeneity of variance: (Equal variance) assume all distributions have the same variance. \
```{r,warning=FALSE}
# We plot the plot Residuals to check for variability as well
plot(model, 1)
# This test was obtained to check if there are significant difference between variances across groups
classdata_update1 %>% 
  levene_test(School_work_hours ~ Group)
```

The residuals graph clearly show that we have some variability in the third group but it is not significant which indicate homogeneity of variances cross groups. We checked it with this test just to make sure that we have equal variances From the output above, we can see that the p-value is > 0.05, which is not significant. This means that, there is not significant difference between variances across groups. Therefore, we can assume the homogeneity of variances in the different groups. \

```{r anova_test}
one.way <- aov(School_work_hours ~ Group, data = classdata_update1)

anova(one.way)
```

There is not significant in the time spent on school work between groups, DF(2, 23) = 0.702, p =  0.506. \
